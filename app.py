import os
import time
import re
import requests
from flask import Flask, render_template, request, jsonify
import google.generativeai as genai
from pymongo import MongoClient
from pymongo.server_api import ServerApi

app = Flask(__name__)

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ (Ø·Ø¨Ù‚ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§) ---
GENERATION_MODEL = "gemini-2.5-flash"
EMBEDDING_MODEL = "models/text-embedding-004"

# --- Ú©Ù„ÛŒØ¯Ù‡Ø§ Ùˆ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ---
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
MONGO_URI = os.environ.get("MONGO_URI")
TAVILY_API_KEY = os.environ.get("TAVILY_API_KEY")

DB_NAME = "my_rag_db"
COLLECTION_NAME = "perplex_context"
INDEX_NAME = "vector_index"

# ØªÙ†Ø¸ÛŒÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
try:
    if not MONGO_URI:
        print("âŒ Error: MONGO_URI is missing.")
        mongo_client = None
        collection = None
    else:
        mongo_client = MongoClient(MONGO_URI, server_api=ServerApi('1'))
        db = mongo_client[DB_NAME]
        collection = db[COLLECTION_NAME]
        # ØªØ³Øª Ø§ØªØµØ§Ù„ Ø³Ø±ÛŒØ¹
        mongo_client.admin.command('ping')
        print("âœ… Connected to MongoDB Atlas Successfully.")
except Exception as e:
    print(f"âŒ DB Connection Error: {e}")
    mongo_client = None
    collection = None

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---

def recursive_chunk_text(text, chunk_size=1000, overlap=100):
    """ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ø¨Ù‡ ØªÚ©Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ± Ø¨Ø§ Ø­ÙØ¸ Ø³Ø§Ø®ØªØ§Ø± Ø¬Ù…Ù„Ø§Øª"""
    if not text: return []
    text = re.sub(r'\s+', ' ', text).strip()
    chunks = []
    start = 0
    text_len = len(text)

    while start < text_len:
        end = start + chunk_size
        if end >= text_len:
            chunks.append(text[start:])
            break
        
        block = text[start:end]
        split_point = -1
        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø´ Ø¯Ø± Ù¾Ø§ÛŒØ§Ù† Ø¬Ù…Ù„Ù‡
        match = re.search(r'[.!?]\s+', block[::-1])
        if match: split_point = len(block) - match.start()
        
        # Ø§Ú¯Ø± Ù†Ø´Ø¯ØŒ Ø¨Ø±Ø´ Ø¯Ø± ÙØ§ØµÙ„Ù‡ Ú©Ù„Ù…Ø§Øª
        if split_point == -1:
            last_space = block.rfind(' ')
            if last_space != -1: split_point = last_space
        
        # Ø§Ú¯Ø± Ú©Ù„Ù…Ù‡ Ø®ÛŒÙ„ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨ÙˆØ¯ØŒ Ø¨Ø±Ø´ Ø³Ø®Øª
        if split_point == -1: split_point = chunk_size
            
        chunks.append(text[start : start + split_point])
        start += split_point - overlap
    return chunks

def get_embedding(text, task_type="retrieval_document"):
    """ØªÙˆÙ„ÛŒØ¯ ÙˆÚ©ØªÙˆØ± Ø¨Ø§ Ù…Ø¯Ù„ 005"""
    if not text or not text.strip(): return None
    try:
        result = genai.embed_content(
            model=EMBEDDING_MODEL,
            content=text,
            task_type=task_type
        )
        return result['embedding']
    except Exception as e:
        print(f"âš ï¸ Embedding Error: {e}")
        return None

def generate_search_queries(prompt):
    """ØªØ¨Ø¯ÛŒÙ„ Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø± Ø¨Ù‡ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ"""
    try:
        model = genai.GenerativeModel(GENERATION_MODEL)
        sys_prompt = (
            f"User prompt: '{prompt}'\n"
            "Generate 3 specific search queries to find information about this prompt. "
            "Return ONLY the queries separated by newlines."
        )
        resp = model.generate_content(sys_prompt)
        return [q.strip() for q in resp.text.split('\n') if q.strip()]
    except:
        return [prompt]

def tavily_search(queries):
    """Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± ÙˆØ¨ Ø¨Ø§ Tavily"""
    if not TAVILY_API_KEY: return []
    combined_results = []
    for q in queries[:2]: 
        try:
            resp = requests.post(
                "https://api.tavily.com/search",
                json={
                    "api_key": TAVILY_API_KEY,
                    "query": q,
                    "search_depth": "basic",
                    "max_results": 3
                }
            )
            data = resp.json()
            if 'results' in data:
                combined_results.extend(data['results'])
        except Exception as e:
            print(f"Tavily Error: {e}")
    return combined_results

# --- Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø³Ø§ÛŒØª ---

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/run_agent', methods=['POST'])
def run_agent():
    if collection is None:
        return jsonify({"error": "Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³"}), 500

    # 1. Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§ÛŒ Ù‚Ø¨Ù„ÛŒ (Session Reset)
    try: 
        collection.delete_many({}) 
        print("ğŸ§¹ Database Cleared.")
    except: pass

    prompt = request.form.get('prompt')
    file = request.files.get('file')
    
    if not prompt: return jsonify({"error": "Ø³ÙˆØ§Ù„ ÙˆØ§Ø±Ø¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª"}), 400

    response_data = {
        "generated_queries": [],
        "all_sources": [],
        "retrieved_chunks": [],
        "answer": "",
        "logs": []
    }
    
    data_inserted = False # Ù¾Ø±Ú†Ù… Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø¯ÛŒØªØ§ÛŒ Ø¬Ø¯ÛŒØ¯ ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡ØŸ

    # 2. Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„
    if file and file.filename != '':
        response_data["logs"].append("ğŸ“‚ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡...")
        try:
            text = file.read().decode('utf-8')
            chunks = recursive_chunk_text(text)
            docs = []
            for ch in chunks:
                emb = get_embedding(ch, task_type="retrieval_document")
                if emb:
                    docs.append({"text": ch, "embedding": emb, "source": "File: " + file.filename})
            if docs:
                collection.insert_many(docs)
                data_inserted = True
                response_data["all_sources"].append({"title": file.filename, "url": "#", "type": "file"})
                response_data["logs"].append(f"âœ… {len(docs)} Ø¨Ø®Ø´ Ø§Ø² ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
        except Exception as e:
            response_data["logs"].append(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙØ§ÛŒÙ„: {str(e)}")

    # 3. Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± ÙˆØ¨
    response_data["logs"].append("ğŸŒ ØªÙˆÙ„ÛŒØ¯ Ú©ÙˆØ¦Ø±ÛŒ Ùˆ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± ÙˆØ¨...")
    queries = generate_search_queries(prompt)
    response_data["generated_queries"] = queries
    
    search_results = tavily_search(queries)
    
    if search_results:
        web_docs = []
        seen_urls = set()
        for res in search_results:
            if res['url'] not in seen_urls:
                response_data["all_sources"].append({"title": res['title'], "url": res['url'], "type": "web"})
                seen_urls.add(res['url'])
            
            content = res.get('content', '')
            if len(content) < 50: continue

            web_chunks = recursive_chunk_text(content, chunk_size=800)
            for ch in web_chunks:
                emb = get_embedding(ch, task_type="retrieval_document")
                if emb:
                    web_docs.append({
                        "text": ch, 
                        "embedding": emb, 
                        "source": res.get('url'),
                        "title": res.get('title')
                    })
        if web_docs:
            collection.insert_many(web_docs)
            data_inserted = True
            response_data["logs"].append(f"ğŸŒ {len(web_docs)} ØªÚ©Ù‡ Ø¯Ø§Ù†Ø´ Ø§Ø² ÙˆØ¨ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

    # --- Ø¨Ø®Ø´ Ø­ÛŒØ§ØªÛŒ: ØµØ¨Ø± Ú©Ø±Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³ ---
    if data_inserted:
        response_data["logs"].append("â³ Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ûµ Ø«Ø§Ù†ÛŒÙ‡ ØµØ¨Ø±)...")
        print("Waiting for Atlas Indexing...")
        time.sleep(5) # Ø§ÛŒÙ† Ø®Ø· Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ù…Ø´Ú©Ù„ Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯Ù† Ø³Ø±Ú† Ø­Ù„ Ø´ÙˆØ¯
    
    # 4. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ (Retrieval)
    response_data["logs"].append("ğŸ¤” Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·...")
    query_emb = get_embedding(prompt, task_type="retrieval_query")
    
    retrieved = []
    if query_emb:
        pipeline = [
            {
                "$vectorSearch": {
                    "index": INDEX_NAME,
                    "path": "embedding",
                    "queryVector": query_emb,
                    "numCandidates": 150,
                    "limit": 10
                }
            },
            {"$project": {"_id": 0, "text": 1, "source": 1, "title": 1, "score": {"$meta": "vectorSearchScore"}}}
        ]
        
        try:
            retrieved = list(collection.aggregate(pipeline))
            print(f"ğŸ¯ Search Results: {len(retrieved)}")
            response_data["retrieved_chunks"] = retrieved
        except Exception as e:
            response_data["logs"].append(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ ÙˆÚ©ØªÙˆØ±: {str(e)}")

    # 5. ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® (Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Fallback)
    response_data["logs"].append("âœï¸ Ù†Ú¯Ø§Ø±Ø´ Ù¾Ø§Ø³Ø® Ù†Ù‡Ø§ÛŒÛŒ...")
    context_text = ""
    
    if retrieved:
        for doc in retrieved:
            src = doc.get('title', doc.get('source'))
            context_text += f"Source ({src}): {doc['text']}\n\n"
    else:
        # Ø§Ú¯Ø± ÙˆÚ©ØªÙˆØ± Ø³Ø±Ú† Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯ØŒ Ø§Ø² Ù…ØªÙ† Ø®Ø§Ù… ÙˆØ¨ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        response_data["logs"].append("âš ï¸ ÙˆÚ©ØªÙˆØ± Ø³Ø±Ú† Ù†ØªÛŒØ¬Ù‡ Ù†Ø¯Ø§Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ ØªØ§Ø®ÛŒØ± Ø§ÛŒÙ†Ø¯Ú©Ø³). Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªÙ† Ø®Ø§Ù….")
        if search_results:
            for res in search_results:
                context_text += f"Source ({res['title']}): {res.get('content', '')[:600]}...\n\n"
        else:
            context_text = "No context found."

    try:
        final_model = genai.GenerativeModel(GENERATION_MODEL)
        final_prompt = (
            f"User Question: {prompt}\n\n"
            f"Based ONLY on the following context, write a comprehensive answer in Persian (Farsi).\n"
            f"Cite sources inline like [Source Name].\n"
            f"If the context is insufficient, say so.\n"
            f"CONTEXT:\n{context_text}"
        )
        answer_resp = final_model.generate_content(final_prompt)
        response_data["answer"] = answer_resp.text
    except Exception as e:
        response_data["answer"] = f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®: {str(e)}"

    return jsonify(response_data)

if __name__ == '__main__':
    app.run(debug=True)
